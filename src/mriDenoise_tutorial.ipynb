{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is designed for one to explore the features of this denoising project. I am using Fastai library, which is built on top of PyTorch. There are several advantages to using Fastai. Ease of use, visualization of whether it be training and valid losses, graphs and images. You could technically run the code from a terminal and still be able to view the graphs and images via terminal. However, I am still in the process of figuring that out and Jupyter notebook will serve as another option until then.\n",
    "\n",
    "The entire tutorial is broken down into following sections:\n",
    "#### 1. Importing all the necessary libararies\n",
    "#### 2. Converting the .nii.gz (nifti images of MRI) into two slices of tiff images\n",
    "#### 3. Creating the Image Databunch \n",
    "#### 4. Creating the model (there are two options)\n",
    "#### 5. Training and saving the model\n",
    "    - finding the optimal learning rate\n",
    "#### 6. Inferencing using the save model\n",
    "#### 7. Calculating the pSNR and SSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sFiGjkJYcIph"
   },
   "source": [
    "# 1. Importing the stadard modules required\n",
    "- Fastai,fastai.vision,fastai.callbacks,fastai.utils.mem: **To do all things Fastai**\n",
    "- torch, torchvision, nn: **For working with PyTorch natively when needed**\n",
    "- os,pathlib: **Deal with paths when working with various files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s35XFi-scIpl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import fastai\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the modules and python functions I created\n",
    "- fileconverter: **To convert 3D niftii files to 2D Tiff Images**\n",
    "- cls_for_reading_tif: **A class to work with tiff files**\n",
    "- create_data_bunch: **To generate dataLoaders to train the models**\n",
    "- models: **A collection of models that one can choose from**\n",
    "- create_Learner: **To train and save the train or intermediate models**\n",
    "- preditor: **To run inference and save the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1667,
     "status": "ok",
     "timestamp": 1569797494481,
     "user": {
      "displayName": "vishwanath somashekar",
      "photoUrl": "",
      "userId": "18129608336523726934"
     },
     "user_tz": 420
    },
    "id": "gF4_ORjeODg0",
    "outputId": "0769a713-8cec-404c-8c4c-b9d93ac0956f"
   },
   "outputs": [],
   "source": [
    "import file_converter\n",
    "import cls_for_reading_tif as clsrt\n",
    "import create_data_bunch as dataFuncs\n",
    "import models as mymodels\n",
    "import create_learner as CL\n",
    "import predictor\n",
    "import calculate_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Converting the nifti files to tiff files\n",
    "After this step, we will have 2D tiff images in train and target folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the location of the 3d nifti image \n",
    "- Enter the location of the ground truth (zero noise)\n",
    "- Enter the location of the image with noise\n",
    "- Enter the location of target images\n",
    "- Enter the location of the train images\n",
    "- Enter the axis along which to take the slices of 2D images\n",
    "- Enter the begin and end of the 3D we want to consider for 2D slice extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_noise = \"/Users/vishwanathsomashekar/Documents/Insight/mriDenoise/data/raw\"\n",
    "source = \"/Users/vishwanathsomashekar/Documents/Insight/mriDenoise/data/preprocessed\" #Enter the source directory here\n",
    "dest_target = \"/Users/vishwanathsomashekar/Documents/Insight/mriDenoise/data/processed/target\" # Enter the destination directory here\n",
    "dest_train = \"/Users/vishwanathsomashekar/Documents/Insight/mriDenoise/data/processed/train\"\n",
    "axis = 1 # the direction along which we want to make the slices\n",
    "startVol = 0.2 # all mri scans of the brain might also have some part of the neck. this start and end vol will make sure we have mostly the brain\n",
    "endVolume = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_converter.conv_niftti_2_tif_noise_truth(source,zero_noise,dest_train,dest_target,axis,startVol,endVolume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating Image Databunch for image size of 45 x 45 pixels\n",
    "Since we don't have enough data to train the network, I have used progressive resizing. The full size image slice is 181 x 181 pixels. So, the idea is:\n",
    "- to create data by resizing to 45 x 45 and train the network\n",
    "- now replace the data with images that are resized to 90 x 90 pixels and further train the network\n",
    "- finally use the full size 181 x 181 images to train it again. \n",
    "\n",
    "Note: all the while, we have not reinitialized the weights of the layers. we are starting from the model that was trained on the previous model size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train = \"/Users/vishwanathsomashekar/Documents/Insight/mriDenoise/data/processed/train\"\n",
    "path_to_target = \"/Users/vishwanathsomashekar/Documents/Insight/mriDenoise/data/processed/target\"\n",
    "bs = 64\n",
    "im_size = 45\n",
    "data_sz_45= dataFuncs.generate_data_bunch(path_to_train,path_to_target,im_size,bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Creating the model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = CL.createLearner(data_sz_45,model_choice=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see the structure of the layers using the summary( ) method of the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal learning rate using lr_find( ) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can plot the results of lr_find( ) using plot( ) method.\n",
    "Choose a learning rate such that the chosen value is in the middle of the steepest slope. It is just an educated guess, and you may have to try different values based on your particular project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training based on learning rate and the num of epochs.\n",
    "The code is written such that the best model during the run is save as **\"best\"** in the models directory in the folder **\"train\"**. You can change the name from \"best\" to anything you deem meaningful. This can be done in the **train_model method in create_learner.py** file. You can then used learner.load(best) method to restart traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first time you run this code, you will not have a best model available. Therefore, you will have to\n",
    "# uncomment the code below and run that\n",
    "#CL.train_model(learner,num_epochs=1,lr=1e-3)\n",
    "CL.train_model(learner,num_epochs=1,lr=1e-3,cont_from_model=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "Once you think you have trained enough this image size, save the model in order to use that to train at a larger image size of 90 x 90 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save(\"a_meaningful_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now create a new databunch like we did before, but this time for a image size of 90 x 90 pixels\n",
    "A general rule of thumb, in order to fit about the same number of images on the GPU, if you doubled the image size, you will need to halve the batch size. I increased the im_size to 90 x 90 and decreased the batch size from 64 to 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "im_size = 90\n",
    "data_sz_90= dataFuncs.generate_data_bunch(path_to_train,path_to_target,im_size,bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load this new databunch into the learner we created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.data = data_sz_90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now train again like before taking the advantae of lr_find and lr.recorder.plot to find an optimal learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot()\n",
    "# the first time you run this code, you will not have a best model available. Therefore, you will have to\n",
    "# uncomment the code below and run that\n",
    "#CL.train_model(learner,num_epochs=1,lr=1e-3)\n",
    "CL.train_model(learner,num_epochs=1,lr=1e-3,cont_from_model=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training enough, save the model with a meaningful name. using learner.save(\"a_meaningful_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow the same procedure as before and resize the image, this time to 181 x 181. Again, a good rule of thumb is to halve the bs everytime we make the image size twice as big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "im_size = 181\n",
    "data_sz_181= dataFuncs.generate_data_bunch(path_to_train,path_to_target,im_size,bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace data in the learner and train like before using the help of lr_find and lr.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.data = data_sz_181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot()\n",
    "# the first time you run this code, you will not have a best model available. Therefore, you will have to\n",
    "# uncomment the code below and run that\n",
    "#CL.train_model(learner,num_epochs=1,lr=1e-3)\n",
    "CL.train_model(learner,num_epochs=1,lr=1e-3,cont_from_model=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally when you have done enough training, export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing\n",
    "Use the predictor.predict(filename) method to inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the below line and change the path to your file. or if you have a lot of images to inference upon,\n",
    "# you can use the predict method in a simple for or while loop. The method will also save a tif file in the same\n",
    "# location as the file with a _predict appended to the file name\n",
    "# filename = \"/Users/vishwanathsomashekar/Documents/Insight/mriDenoise/data/processed/train/t1_icbm_normal_1mm_pn1_rf0_48.tif\"\n",
    "predictor.predict(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the input and the predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pAmm_1kpkkM2"
   },
   "outputs": [],
   "source": [
    "# im = os.path.join(root_dir, \"train\",\"t1_icbm_normal_1mm_pn3_rf0_50.tif\" )#\"/content/gdrive/My Drive/data/train/t1_icbm_normal_1mm_pn3_rf0_50.tif\"\n",
    "im_input = \"/home/ubuntu/mriDenoise/data/processed/train/t1_icbm_normal_1mm_pn9_rf0_50.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2074,
     "status": "ok",
     "timestamp": 1569794235852,
     "user": {
      "displayName": "vishwanath somashekar",
      "photoUrl": "",
      "userId": "18129608336523726934"
     },
     "user_tz": 420
    },
    "id": "rBp3MAwvlFdF",
    "outputId": "a28e98ea-cb3d-4ba3-b548-4dc7cb1280c6"
   },
   "outputs": [],
   "source": [
    "im1 = open_tiff(im_input)\n",
    "im1.show(cmap='gray', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pAmm_1kpkkM2"
   },
   "outputs": [],
   "source": [
    "# im = os.path.join(root_dir, \"train\",\"t1_icbm_normal_1mm_pn3_rf0_50.tif\" )#\"/content/gdrive/My Drive/data/train/t1_icbm_normal_1mm_pn3_rf0_50.tif\"\n",
    "im_predicted = \"/home/ubuntu/mriDenoise/data/processed/train/t1_icbm_normal_1mm_pn9_rf0_50_predict.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2074,
     "status": "ok",
     "timestamp": 1569794235852,
     "user": {
      "displayName": "vishwanath somashekar",
      "photoUrl": "",
      "userId": "18129608336523726934"
     },
     "user_tz": 420
    },
    "id": "rBp3MAwvlFdF",
    "outputId": "a28e98ea-cb3d-4ba3-b548-4dc7cb1280c6"
   },
   "outputs": [],
   "source": [
    "im2 = open_tiff(im_predicted)\n",
    "im2.show(cmap='gray', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr_before,ssim_ = calculate_metrics(im_zero_noise,im1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Tg26PIwpcIqE",
    "pSz4MbJdcIqZ",
    "Wu1IVtuocIq9"
   ],
   "name": "mriDenoise_kashy.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
